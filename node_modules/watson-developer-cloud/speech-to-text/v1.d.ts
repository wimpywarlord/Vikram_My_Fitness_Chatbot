/// <reference types="node" />
import RecognizeStream = require('../lib/recognize-stream');
import GeneratedSpeechToTextV1 = require('./v1-generated');
declare class SpeechToTextV1 extends GeneratedSpeechToTextV1 {
    static ERR_NO_CORPORA: string;
    static ERR_TIMEOUT: string;
    constructor(options: any);
    getModels(params: any, callback: any): void | NodeJS.ReadableStream;
    getCustomization(params: any, callback: any): void | NodeJS.ReadableStream;
    getRecognitionJob(params: any, callback: any): void | NodeJS.ReadableStream;
    createCustomization(params: any, callback: any): void | NodeJS.ReadableStream;
    getRecognitionJobs(params: any, callback: any): void | NodeJS.ReadableStream;
    deleteRecognitionJob(params: any, callback: any): void | NodeJS.ReadableStream;
    getCustomizations(params: any, callback: any): void | NodeJS.ReadableStream;
    createRecognitionJob(params: any, callback: any): void | NodeJS.ReadableStream;
    addCorpus(params: any, callback: any): void | NodeJS.ReadableStream;
    getCorpus(params: any, callback: any): void | NodeJS.ReadableStream;
    deleteCorpus(params: any, callback: any): void | NodeJS.ReadableStream;
    getCorpora(params: any, callback: any): void | NodeJS.ReadableStream;
    addWords(params: any, callback: any): void | NodeJS.ReadableStream;
    addWord(params: any, callback: any): void | NodeJS.ReadableStream;
    getWords(params: any, callback: any): void | NodeJS.ReadableStream;
    getWord(params: any, callback: any): void | NodeJS.ReadableStream;
    deleteWord(params: any, callback: any): void | NodeJS.ReadableStream;
    trainCustomization(params: any, callback: any): void | NodeJS.ReadableStream;
    resetCustomization(params: any, callback: any): void | NodeJS.ReadableStream;
    /**
     * Waits while corpora analysis status is 'being_processes', fires callback once the status is 'analyzed'
     *
     * Note: the code will throw an error in case there in no corpus in the customization
     *
     *
     * @param {Object} params The parameters
     * @param {String} params.customization_id - The GUID of the custom language model
     * @param {Number} [params.interval=5000] - (milliseconds) - how long to wait between status checks
     * @param {Number} [params.times=30] - maximum number of attempts
     * @param {Function} callback
     */
    whenCorporaAnalyzed(params: any, callback: any): void;
    /**
     * Creates a HTTP/HTTPS request to /recognize and keep the connection open.
     * Sets 'Transfer-Encoding': 'chunked' and prepare the connection to send
     * chunk data.
     *
     * @deprecated use createRecognizeStream instead
     *
     * @param {Object} params The parameters
     * @param {String} [params.content_type] - The Content-type e.g. audio/l16; rate=48000
     * @param {String} [params.session_id] - The session id
     * @param {function} callback
     */
    recognizeLive(params: any, callback: any): any;
    /**
     * Result observer for upcoming or ongoing recognition task in the session.
     * This request has to be started before POST on recognize finishes,
     * otherwise it waits for the next recognition.
     *
     * @deprecated use createRecognizeStream instead
     *
     * @param {Object} params The parameters
     * @param {String} [params.session_id] - Session used in the recognition
     * @param {boolean} [params.interim_results] - If true, interim results will be returned. Default: false
     * @param {Function} callback
     */
    observeResult(params: any, callback: any): any;
    /**
     * Replaces recognizeLive & friends with a single 2-way stream over websockets
     *
     * @param {Object} params The parameters
     * @return {RecognizeStream}
     */
    createRecognizeStream(params: any): RecognizeStream;
    /**
     * Speech recognition for given audio using default model.
     *
     * @param {Object} params The parameters
     * @param {Stream} params.audio - Audio to be recognized
     * @param {String} params.content_type - Content-type
     * @param {Boolean} [params.continuous]
     * @param {Number} [params.max_alternatives]
     * @param {Boolean} [params.timestamps]
     * @param {Boolean} [params.word_confidence]
     * @param {Number} [params.inactivity_timeout]
     * @param {String} [params.model]
     * @param {Boolean} [params.interim_results]
     * @param {Boolean} [params.keywords]
     * @param {Number} [params.keywords_threshold]
     * @param {Number} [params.word_alternatives_threshold]
     * @param {Boolean} [params.profanity_filter]
     * @param {Boolean} [params.smart_formatting]
     * @param {String} [params.customization_id]
     * @param {Boolean} [params.speaker_labels]
     * @param {function} callback
     */
    recognize(params: any, callback: any): any;
    deleteCustomization(params: any, callback: any): void | NodeJS.ReadableStream;
    /**
     * Waits while a customization status is 'pending' or 'training', fires callback once the status is 'ready' or 'available'.
     *
     * Note: the customization will remain in 'pending' status until at least one word corpus is added.
     *
     * See http://www.ibm.com/watson/developercloud/speech-to-text/api/v1/#list_models for status details.
     *
     * @param {Object} params The parameters
     * @param {String} params.customization_id - The GUID of the custom language model
     * @param {Number} [params.interval=5000] - (milliseconds) - how log to wait between status checks
     * @param {Number} [params.times=30] - maximum number of attempts
     * @param {Function} callback
     */
    whenCustomizationReady(params: any, callback: any): void;
}
export = SpeechToTextV1;
